/*
AVX Utility Functions and Classification
*/

#include "avx_utils.h"
#include "avx_helpers.h"

#if IDA_SDK_VERSION >= 750

int get_op_size(const insn_t &insn) {
    if (is_xmm_reg(insn.Op1)) return XMM_SIZE;
    if (is_ymm_reg(insn.Op1)) return YMM_SIZE;
    if (is_zmm_reg(insn.Op1)) return ZMM_SIZE;
    return XMM_SIZE;
}

qstring make_intrinsic_name(const char *fmt, int op_size) {
    qstring n;
    const char *prefix = "";
    if (op_size == ZMM_SIZE) prefix = "512";
    else if (op_size == YMM_SIZE) prefix = "256";
    n.cat_sprnt(fmt, prefix);
    return n;
}

tinfo_t get_type_robust(int op_size, bool is_int, bool is_double) {
    return get_vector_type(op_size, is_int, is_double);
}

//----- AVXâ†’SSE simple aliases
struct InsnMapping {
    uint16 avx_itype;
    uint16 sse_itype;
};

// NOTE: keep only aliases that do NOT write an XMM destination (thus no VEX.128 zero-upper is required)
static constexpr InsnMapping avx_to_sse_map[] =
{
    // flag-setting compares (no XMM dest write)
    {NN_vcomiss, NN_comiss}, {NN_vcomisd, NN_comisd}, {NN_vucomiss, NN_ucomiss}, {NN_vucomisd, NN_ucomisd},
    // extract to GPR/mem (no XMM dest write)
    {NN_vpextrb, NN_pextrb}, {NN_vpextrw, NN_pextrw}, {NN_vpextrd, NN_pextrd}, {NN_vpextrq, NN_pextrq},
    // int conversions to GPR (dest is GPR)
    {NN_vcvttss2si, NN_cvttss2si}, {NN_vcvttsd2si, NN_cvttsd2si}, {NN_vcvtsd2si, NN_cvtsd2si}
};

bool try_convert_to_sse(codegen_t &cdg) {
    for (size_t i = 0; i < qnumber(avx_to_sse_map); i++)
        if (cdg.insn.itype == avx_to_sse_map[i].avx_itype) {
            cdg.insn.itype = avx_to_sse_map[i].sse_itype;
            return true;
        }
    return false;
}

//----- classification
bool is_compare_insn(uint16 it) {
    return it == NN_vcomiss || it == NN_vcomisd || it == NN_vucomiss || it == NN_vucomisd;
}

bool is_extract_insn(uint16 it) {
    return it == NN_vpextrb || it == NN_vpextrw || it == NN_vpextrd || it == NN_vpextrq;
}

bool is_conversion_insn(uint16 it) {
    return it == NN_vcvttss2si || it == NN_vcvtdq2ps || it == NN_vcvtsi2ss || it == NN_vcvtps2pd ||
           it == NN_vcvtss2sd || it == NN_vcvttsd2si || it == NN_vcvtsd2si || it == NN_vcvtpd2ps ||
           it == NN_vcvttpd2dq || it == NN_vcvtpd2dq || it == NN_vcvttps2dq || it == NN_vcvtps2dq ||
           it == NN_vcvtsi2sd || it == NN_vcvtsd2ss || it == NN_vcvtdq2pd;
}

bool is_sad_insn(uint16 it) {
    return it == NN_vpsadbw || it == NN_vmpsadbw;
}

bool is_move_insn(uint16 it) {
    // Note: vmovss/vmovsd scalar moves are excluded to let IDA handle them natively
    return it == NN_vmovd || it == NN_vmovq ||
           it == NN_vmovaps || it == NN_vmovups || it == NN_vmovdqa || it == NN_vmovdqu ||
           it == NN_vmovapd || it == NN_vmovupd ||
           // AVX-512 move variants
           it == NN_vmovdqa32 || it == NN_vmovdqa64 ||
           it == NN_vmovdqu8 || it == NN_vmovdqu16 || it == NN_vmovdqu32 || it == NN_vmovdqu64;
}

bool is_bitwise_insn(uint16 it) {
    return it == NN_vpor || it == NN_vorps || it == NN_vorpd ||
           it == NN_vpand || it == NN_vandps || it == NN_vandpd ||
           it == NN_vpxor || it == NN_vxorps || it == NN_vxorpd ||
           it == NN_vandnps || it == NN_vandnpd || it == NN_vpandn;
}

bool is_scalar_minmax(uint16 it) {
    return it == NN_vminss || it == NN_vminsd || it == NN_vmaxss || it == NN_vmaxsd;
}

bool is_scalar_math(uint16 it) {
    return it == NN_vaddss || it == NN_vsubss || it == NN_vmulss || it == NN_vdivss ||
           it == NN_vaddsd || it == NN_vsubsd || it == NN_vmulsd || it == NN_vdivsd;
}

bool is_scalar_move(uint16 it) {
    return it == NN_vmovss || it == NN_vmovsd;
}

bool is_vzeroupper(uint16 it) {
    return it == NN_vzeroupper;
}

bool is_packed_minmax_fp(uint16 it) {
    return it == NN_vminps || it == NN_vminpd || it == NN_vmaxps || it == NN_vmaxpd;
}

bool is_packed_minmax_int(uint16 it) {
    return it == NN_vpminsb || it == NN_vpminsw || it == NN_vpminsd ||
           it == NN_vpminub || it == NN_vpminuw || it == NN_vpminud ||
           it == NN_vpmaxsb || it == NN_vpmaxsw || it == NN_vpmaxsd ||
           it == NN_vpmaxub || it == NN_vpmaxuw || it == NN_vpmaxud;
}

bool is_int_mul(uint16 it) {
    return it == NN_vpmullw || it == NN_vpmulld || it == NN_vpmulhw || it == NN_vpmulhuw ||
           it == NN_vpmuldq || it == NN_vpmuludq || it == NN_vpmaddwd || it == NN_vpmaddubsw;
}

bool is_avg_insn(uint16 it) {
    return it == NN_vpavgb || it == NN_vpavgw;
}

bool is_abs_insn(uint16 it) {
    return it == NN_vpabsb || it == NN_vpabsw || it == NN_vpabsd;
}

bool is_sign_insn(uint16 it) {
    return it == NN_vpsignb || it == NN_vpsignw || it == NN_vpsignd;
}

bool is_shift_insn(uint16 it) {
    return it == NN_vpsllw || it == NN_vpslld || it == NN_vpsllq ||
           it == NN_vpsrlw || it == NN_vpsrld || it == NN_vpsrlq ||
           it == NN_vpsraw || it == NN_vpsrad;
}

bool is_var_shift_insn(uint16 it) {
    return it == NN_vpsllvd || it == NN_vpsllvq ||
           it == NN_vpsrlvd || it == NN_vpsrlvq ||
           it == NN_vpsravd;
}

bool is_shuffle_insn(uint16 it) {
    return it == NN_vpshufb || it == NN_vpshufd || it == NN_vpshufhw || it == NN_vpshuflw;
}

bool is_perm_insn(uint16 it) {
    return it == NN_vpermq || it == NN_vpermd || it == NN_vpermilps || it == NN_vpermilpd;
}

bool is_align_insn(uint16 it) {
    return it == NN_vpalignr;
}

bool is_gather_insn(uint16 it) {
    return it == NN_vgatherdps || it == NN_vgatherdpd ||
           it == NN_vpgatherdd || it == NN_vpgatherdq;
}

bool is_fma_insn(uint16 it) {
    return (it >= NN_vfmadd132ps && it <= NN_vfmadd231sd) ||
           (it >= NN_vfmsub132ps && it <= NN_vfmsub231sd) ||
           (it >= NN_vfnmadd132ps && it <= NN_vfnmadd231sd) ||
           (it >= NN_vfnmsub132ps && it <= NN_vfnmsub231sd);
}

bool is_math_insn(uint16 it) {
    // Note: Scalar operations (vaddss/sd, vsubss/sd, vmulss/sd, vdivss/sd) are excluded
    // to let IDA handle them natively, avoiding type/verification issues
    return it == NN_vaddps || it == NN_vsubps || it == NN_vmulps || it == NN_vdivps ||
           it == NN_vaddpd || it == NN_vsubpd || it == NN_vmulpd || it == NN_vdivpd ||
           it == NN_vpaddb || it == NN_vpsubb || it == NN_vpaddw || it == NN_vpsubw ||
           it == NN_vpaddd || it == NN_vpsubd || it == NN_vpaddq || it == NN_vpsubq ||
           it == NN_vpaddsb || it == NN_vpsubsb || it == NN_vpaddsw || it == NN_vpsubsw ||
           is_packed_minmax_fp(it) || is_packed_minmax_int(it) || is_int_mul(it) ||
           is_avg_insn(it) || is_abs_insn(it) || is_sign_insn(it) ||
           is_shift_insn(it) || is_var_shift_insn(it) ||
           is_shuffle_insn(it) || is_perm_insn(it) || is_align_insn(it) ||
           is_gather_insn(it) || is_fma_insn(it);
}

bool is_broadcast_insn(uint16 it) {
    return it == NN_vbroadcastss || it == NN_vbroadcastsd || it == NN_vbroadcastf128 || it == NN_vbroadcasti128;
}

bool is_misc_insn(uint16 it) {
    return it == NN_vsqrtss || it == NN_vsqrtps || it == NN_vsqrtpd ||
           it == NN_vshufps || it == NN_vshufpd ||
           it == NN_vpermpd;
}

bool is_extract_insert_insn(uint16 it) {
    return it == NN_vextractf128 || it == NN_vinsertf128 ||
           it == NN_vextracti128 || it == NN_vinserti128;
}

bool is_movdup_insn(uint16 it) {
    return it == NN_vmovshdup || it == NN_vmovsldup ||
           it == NN_vmovddup;
}

bool is_unpack_insn(uint16 it) {
    return it == NN_vunpckhps || it == NN_vunpcklps ||
           it == NN_vunpckhpd || it == NN_vunpcklpd;
}

bool is_blend_insn(uint16 it) {
    return it == NN_vblendvps || it == NN_vblendvpd ||
           it == NN_vblendps || it == NN_vblendpd ||
           it == NN_vpblendd || it == NN_vpblendw || it == NN_vpblendvb;
}

bool is_maskmov_insn(uint16 it) { return it == NN_vmaskmovps || it == NN_vmaskmovpd; }

bool is_packed_compare_insn(uint16 it) {
    return (it >= NN_vcmpeqps && it <= NN_vcmptrue_usps) ||
           (it >= NN_vcmpeqpd && it <= NN_vcmptrue_uspd) ||
           (it >= NN_vcmpeqss && it <= NN_vcmptrue_usss) ||
           (it >= NN_vcmpeqsd && it <= NN_vcmptrue_ussd);
}

bool is_packed_int_compare_insn(uint16 it) {
    return it == NN_vpcmpeqb || it == NN_vpcmpeqw || it == NN_vpcmpeqd || it == NN_vpcmpeqq ||
           it == NN_vpcmpgtb || it == NN_vpcmpgtw || it == NN_vpcmpgtd || it == NN_vpcmpgtq;
}

uint8 get_cmp_predicate(uint16 it) {
    if (it >= NN_vcmpeqps && it <= NN_vcmptrue_usps) return (uint8) (it - NN_vcmpeqps);
    if (it >= NN_vcmpeqpd && it <= NN_vcmptrue_uspd) return (uint8) (it - NN_vcmpeqpd);
    if (it >= NN_vcmpeqss && it <= NN_vcmptrue_usss) return (uint8) (it - NN_vcmpeqss);
    if (it >= NN_vcmpeqsd && it <= NN_vcmptrue_ussd) return (uint8) (it - NN_vcmpeqsd);
    return 0;
}

bool is_horizontal_math(uint16 it) {
    return it == NN_vhaddps || it == NN_vhaddpd || it == NN_vhsubps || it == NN_vhsubpd ||
           it == NN_vphaddw || it == NN_vphaddsw || it == NN_vphaddd || it == NN_vphsubd;
}

bool is_dot_product(uint16 it) {
    return it == NN_vdpps;
}

bool is_approx_insn(uint16 it) {
    return it == NN_vrcpps || it == NN_vrsqrtps;
}

bool is_scalar_approx_insn(uint16 it) {
    return it == NN_vrcpss || it == NN_vrsqrtss;
}

bool is_round_insn(uint16 it) {
    return it == NN_vroundps || it == NN_vroundpd;
}

bool is_scalar_round_insn(uint16 it) {
    return it == NN_vroundss || it == NN_vroundsd;
}

bool is_addsub_insn(uint16 it) {
    return it == NN_vaddsubps || it == NN_vaddsubpd;
}

bool is_vpbroadcast_d_q(uint16 it) {
    return it == NN_vpbroadcastd || it == NN_vpbroadcastq;
}

bool is_vperm2_insn(uint16 it) {
    return it == NN_vperm2f128 || it == NN_vperm2i128;
}

bool is_phsub_insn(uint16 it) {
    return it == NN_vphsubw || it == NN_vphsubsw || it == NN_vphsubd;
}

bool is_pack_insn(uint16 it) {
    return it == NN_vpackssdw || it == NN_vpacksswb ||
           it == NN_vpackusdw || it == NN_vpackuswb;
}

bool is_ptest_insn(uint16 it) {
    return it == NN_vptest;
}

bool is_fmaddsub_insn(uint16 it) {
    return (it >= NN_vfmaddsub132ps && it <= NN_vfmaddsub231pd) ||
           (it >= NN_vfmsubadd132ps && it <= NN_vfmsubadd231pd);
}

bool is_movmsk_insn(uint16 it) {
    return it == NN_vmovmskps || it == NN_vmovmskpd || it == NN_vpmovmskb;
}

bool is_movnt_insn(uint16 it) {
    return it == NN_vmovntps || it == NN_vmovntpd || it == NN_vmovntdq;
}

bool is_vpbroadcast_b_w(uint16 it) {
    return it == NN_vpbroadcastb || it == NN_vpbroadcastw;
}

bool is_pinsert_insn(uint16 it) {
    return it == NN_vpinsrb || it == NN_vpinsrw || it == NN_vpinsrd || it == NN_vpinsrq;
}

bool is_pmovsx_insn(uint16 it) {
    return it == NN_vpmovsxbw || it == NN_vpmovsxbd || it == NN_vpmovsxbq ||
           it == NN_vpmovsxwd || it == NN_vpmovsxwq || it == NN_vpmovsxdq;
}

bool is_pmovzx_insn(uint16 it) {
    return it == NN_vpmovzxbw || it == NN_vpmovzxbd || it == NN_vpmovzxbq ||
           it == NN_vpmovzxwd || it == NN_vpmovzxwq || it == NN_vpmovzxdq;
}

bool is_byte_shift_insn(uint16 it) {
    return it == NN_vpslldq || it == NN_vpsrldq;
}

bool is_punpck_insn(uint16 it) {
    return it == NN_vpunpckhbw || it == NN_vpunpcklbw ||
           it == NN_vpunpckhwd || it == NN_vpunpcklwd ||
           it == NN_vpunpckhdq || it == NN_vpunpckldq ||
           it == NN_vpunpckhqdq || it == NN_vpunpcklqdq;
}

bool is_extractps_insn(uint16 it) {
    return it == NN_vextractps;
}

bool is_insertps_insn(uint16 it) {
    return it == NN_vinsertps;
}

qstring make_masked_intrinsic_name(const char *base_name, const MaskInfo &mask_info) {
    if (!mask_info.has_mask) {
        return qstring(base_name);
    }

    // Find the position after "_mm" or "_mm256" or "_mm512" prefix
    // Pattern: _mm[256|512]_<op>_<type>
    // Masked: _mm[256|512]_mask[z]_<op>_<type>
    qstring result;
    const char *p = base_name;

    // Copy "_mm" prefix
    if (strncmp(p, "_mm", 3) == 0) {
        result.append("_mm");
        p += 3;

        // Check for "256" or "512" suffix
        if (strncmp(p, "512", 3) == 0) {
            result.append("512");
            p += 3;
        } else if (strncmp(p, "256", 3) == 0) {
            result.append("256");
            p += 3;
        }

        // Skip the underscore before operation name
        if (*p == '_') {
            result.append("_");
            p++;
        }

        // Insert "mask" or "maskz"
        if (mask_info.is_zeroing) {
            result.append("maskz_");
        } else {
            result.append("mask_");
        }

        // Append the rest (operation and type suffix)
        result.append(p);
    } else {
        // Fallback: just return original name
        result = base_name;
    }

    return result;
}

#endif // IDA_SDK_VERSION >= 750
